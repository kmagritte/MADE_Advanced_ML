{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from nltk import everygrams\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "np.random.seed(4)\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "RE_RU = re.compile(\"[^а-я ]*\")\n",
    "RE_EN = re.compile(\"[^a-z ]*\")\n",
    "\n",
    "SPACE = \" \"\n",
    "ALPHABET_RU = \"абвгдежзийклмнопрстуфхцчшщъыьэюя\" + SPACE\n",
    "\n",
    "\n",
    "TEST = \"\"\"\n",
    "Только окончится один месяц, сразу же начинается другой. И ни разу еще не бывало так, \\\n",
    "чтобы февраль пришел раньше, чем уйдет январь, а май обогнал бы апрель. \\\n",
    "Месяцы идут один за другим и никогда не встречаются. \\\n",
    "Но люди рассказывают, будто в горной стране Богемии была девочка, которая видела все двенадцать месяцев сразу. \\\n",
    "Как же это случилось? А вот как. \\\n",
    "В одной маленькой деревушке жила злая и скупая женщина с дочкой и падчерицей. \\\n",
    "Дочку она любила, а падчерица ничем ей не могла угодить. \\\n",
    "Что ни сделает падчерица — все не так, как ни повернется — все не в ту сторону. \\ \n",
    "Дочка по целым дням на перине валялась да пряники ела, а падчерице с утра до ночи и присесть некогда было: \\\n",
    "то воды натаскай, то хворосту из лесу привези, то белье на речке выполощи, то грядки в огороде выполи. \\\n",
    "Знала она и зимний холод, и летний зной, и весенний ветер, и осенний дождь. \\\n",
    "Потому-то, может, и довелось ей однажды увидеть все двенадцать месяцев разом. \\\n",
    "Была зима. Шел январь месяц. Снегу намело столько, что от дверей его приходилось отгребать лопатами, \\\n",
    "а в лесу на горе деревья стояли по пояс в сугробах и даже качаться не могли, когда на них налетал ветер. \\\n",
    "Люди сидели в домах и топили печки.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "with open(os.path.join(DATA_PATH, \"AnnaKarenina.txt\"), \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "    texts.append(re.sub(RE_RU, \"\", text.lower()))\n",
    "    \n",
    "with open(os.path.join(DATA_PATH, \"WarAndPeace.txt\"), \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "    texts.append(re.sub(RE_RU, \"\", text.lower()))\n",
    "    \n",
    "with open(os.path.join(DATA_PATH, \"WarAndPeaceEng.txt\"), \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "    texts.append(re.sub(RE_EN, \"\", text.lower()))\n",
    "\n",
    "test_ru = re.sub(RE_RU, \"\", TEST.lower())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Раздел 1. Базовый частотный метод\n",
    "Реализуем базовый частотный метод по Шерлоку Холмсу:\n",
    "- подсчитаем частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);  \n",
    "- возьмем какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруем их посредством случайной перестановки символов;  \n",
    "- расшифруем их таким частотным методом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_freq(text: str, n_gram: int=1) -> Dict:\n",
    "    \n",
    "    freq = Counter()\n",
    "    for group_begin in range(len(text) + 1 - n_gram):\n",
    "        group = text[group_begin : group_begin + n_gram]\n",
    "        freq[group] += 1\n",
    "\n",
    "    for key in freq:\n",
    "        freq[key] /= len(text)\n",
    "\n",
    "    return freq\n",
    "\n",
    "\n",
    "corpus_freq = get_ngram_freq(texts[0] + \" \" + texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mapping(freq: Dict) -> Dict:\n",
    "    original = list(freq.keys())\n",
    "    replacement = np.random.choice(original, replace=False, size=len(freq))\n",
    "    mapping = {\n",
    "        original_char: replacement_char\n",
    "        for original_char, replacement_char in zip(original, replacement)\n",
    "    }\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def generate_reverse_mapping(corpus_freq: Dict, text_freq: Dict, n_gram: int=1):\n",
    "    corpus_freq_sorted = sorted(corpus_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    text_freq_sorted = sorted(text_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    reverse_mapping = {}\n",
    "    for text_ngram, text_freq in text_freq_sorted:\n",
    "        filtered_freq = copy(corpus_freq_sorted)\n",
    "\n",
    "        for j in range(n_gram):\n",
    "            if text_ngram[j] in reverse_mapping:\n",
    "                filtered_freq = [\n",
    "                    (ngram, freq) for ngram, freq in filtered_freq\n",
    "                    if ngram[j] == reverse_mapping[text_ngram[j]]\n",
    "                ]\n",
    "\n",
    "        min_diff = 1\n",
    "        best_ngram = None\n",
    "        for ngram, freq in filtered_freq:\n",
    "            diff = abs(freq - text_freq)\n",
    "            if diff < min_diff:\n",
    "                best_ngram = ngram\n",
    "                min_diff = diff\n",
    "\n",
    "        for j in range(n_gram):\n",
    "            if text_ngram[j] not in reverse_mapping:\n",
    "                reverse_mapping[text_ngram[j]] = best_ngram[j]\n",
    "\n",
    "    return reverse_mapping\n",
    "\n",
    "\n",
    "mapping = generate_mapping(corpus_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mapping(text: str, mapping: Dict) -> str:\n",
    "    \n",
    "    new_text = \"\"\n",
    "    n_gram = len(list(mapping.keys())[0])\n",
    "    for i in range(0, len(text) // n_gram * n_gram, n_gram):\n",
    "        new_text += mapping.get(text[i: i + n_gram])\n",
    "    return new_text\n",
    "\n",
    "\n",
    "test_encoded = apply_mapping(test_ru, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_freq = get_ngram_freq(test_encoded)\n",
    "reverse_mapping = generate_reverse_mapping(corpus_freq, encoded_freq)\n",
    "test_decoded = apply_mapping(test_encoded, reverse_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(text, text_decoded):\n",
    "    correct = sum((char == char_d) for char, char_d in zip(text, text_decoded))\n",
    "    return correct / len(text)\n",
    "\n",
    "\n",
    "def describe(text=None, encoded=None, decoded=None, char_per_line=130):\n",
    "    if text:\n",
    "        print(\n",
    "            \"Исходный текст:\",\n",
    "            *[text[i:i + char_per_line]for i in range(0, len(text), char_per_line)], \n",
    "            \"\\n\",\n",
    "            end=\"\", \n",
    "            sep=\"\\n\"\n",
    "            )\n",
    "        \n",
    "    if encoded:\n",
    "        print(\n",
    "            \"Закодированный текст:\",\n",
    "            *[encoded[i:i + char_per_line] for i in range(0, len(encoded), char_per_line)], \n",
    "            \"\\n\",\n",
    "            end=\"\", \n",
    "            sep=\"\\n\"\n",
    "            )\n",
    "    \n",
    "    if decoded:\n",
    "        print(\n",
    "            \"Декодированный текст:\",\n",
    "            *[decoded[i:i + char_per_line] for i in range(0, len(decoded), char_per_line)], \n",
    "            \"\\n\",\n",
    "            end=\"\", \n",
    "            sep=\"\\n\"\n",
    "            )\n",
    "    \n",
    "    if text and decoded:\n",
    "        print(\"Точность:\", accuracy(text, decoded), \"\\n\", end=\"\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст:\n",
      "только окончится один месяц сразу же начинается другой и ни разу еще не бывало так чтобы февраль пришел раньше чем уйдет январь а \n",
      "май обогнал бы апрель месяцы идут один за другим и никогда не встречаются но люди рассказывают будто в горной стране богемии была \n",
      "девочка которая видела все двенадцать месяцев сразу как же это случилось а вот как в одной маленькой деревушке жила злая и скупая \n",
      "женщина с дочкой и падчерицей дочку она любила а падчерица ничем ей не могла угодить что ни сделает падчерица  все не так как ни п\n",
      "овернется  все не в ту сторону  дочка по целым дням на перине валялась да пряники ела а падчерице с утра до ночи и присесть некогд\n",
      "а было то воды натаскай то хворосту из лесу привези то белье на речке выполощи то грядки в огороде выполи знала она и зимний холод\n",
      " и летний зной и весенний ветер и осенний дождь потомуто может и довелось ей однажды увидеть все двенадцать месяцев разом была зим\n",
      "а шел январь месяц снегу намело столько что от дверей его приходилось отгребать лопатами а в лесу на горе деревья стояли по пояс в\n",
      " сугробах и даже качаться не могли когда на них налетал ветер люди сидели в домах и топили печки\n",
      "\n",
      "Закодированный текст:\n",
      "ж ксщ т щ шымжяэт ймштучяэбтявльзточтшлымшлчжяэтйвзи цтмтшмтвльзтчнчтшчтдпалк тжлщтыж дптючавлкстхвмрчктвлшсрчтычутзцйчжтэшалвстлт\n",
      "улцт д ишлктдптлхвчкстучяэбптмйзжт ймштьлтйвзимутмтшмщ ийлтшчтаяжвчылфжяэтш ткфймтвляящльпалфжтдзйж тати вш цтяжвлшчтд ичуммтдпклт\n",
      "йча ыщлтщ ж влэтамйчклтаячтйачшлйблжстучяэбчатявльзтщлщточтгж тякзымк ястлта жтщлщтат йш цтулкчшсщ цтйчвчазрщчтомклтьклэтмтящзхлэт\n",
      "очшнмшлтятй ыщ цтмтхлйычвмбчцтй ыщзт шлткфдмклтлтхлйычвмблтшмычутчцтшчту иклтзи ймжстыж тшмтяйчклчжтхлйычвмблттаячтшчтжлщтщлщтшмтх\n",
      " ачвшчжяэттаячтшчтатжзтяж в шзттй ыщлтх тбчкпутйшэутшлтхчвмшчталкэклястйлтхвэшмщмтчклтлтхлйычвмбчтятзжвлтй тш ымтмтхвмячяжстшчщ ий\n",
      "лтдпк тж та йптшлжлящлцтж тъа в яжзтмьткчязтхвмачьмтж тдчксчтшлтвчыщчтапх к нмтж тивэйщмтат и в йчтапх кмтьшлклт шлтмтьмушмцтъ к й\n",
      "тмткчжшмцтьш цтмтачячшшмцтачжчвтмт ячшшмцтй ойстх ж узж ту очжтмтй ачк ястчцт йшлойптзамйчжстаячтйачшлйблжстучяэбчатвль утдпклтьму\n",
      "лтрчктэшалвстучяэбтяшчизтшлучк тяж ксщ тыж т жтйачвчцтчи тхвмъ ймк яст живчдлжстк хлжлумтлтаткчязтшлти вчтйчвчасэтяж экмтх тх эята\n",
      "тязив длътмтйлочтщлылжсяэтшчту икмтщ ийлтшлтшмътшлкчжлктачжчвткфймтямйчкмтатй улътмтж хмкмтхчыщм\n",
      "\n",
      "Декодированный текст:\n",
      "севпде едетянсвп елнт певпж вречп ше теянтеесвп лрпгеб н тн речп еце те ччреве сед ясечч ферревп прнэев ретпэе яеп пблес птрерп е \n",
      "пеб ечегтев чч епревп певпжч нлпс елнт че лрпгнп н тндегле те рвсреяеюсвп те вюлн реввдеччреюс чплсе р гертеб всрете чегепнн ччве \n",
      "лереяде десереп рнлеве рве лретелжесп певпжер вречп дед ше фсе ввпянвевп е рес дед р елтеб певетпдеб лерерпэде шнве чвеп н вдппеп \n",
      "шетцнте в леядеб н пеляернжеб леядп ете вючнве е пеляернже тняеп еб те пегве пгелнсп ясе тн влевеес пеляернже  рве те сед дед тн п\n",
      "ерертесвп  рве те р сп всеретп  леяде пе жевчп лтпп те пернте ревпвевп ле прптндн еве е пеляернже в псре ле теян н прнвевсп тедегл\n",
      "е ччве се релч тесевдеб се юреревсп нч вевп прнречн се чевпе те реяде рчпевецн се грплдн р егереле рчпевн чтеве ете н чнптнб юевел\n",
      " н вестнб чтеб н реветтнб ресер н еветтнб лешлп песеппсе пешес н леревевп еб елтешлч прнлесп рве лретелжесп певпжер речеп ччве чнп\n",
      "е эев птрерп певпж втегп тепеве всевпде ясе ес лререб еге прнюелнвевп есгречесп вепесепн е р вевп те гере лерерпп всепвн пе пепв р\n",
      " впгречею н леше деяеспвп те пегвн дегле те тню тевесев ресер вюлн внлевн р лепею н сепнвн пеядн\n",
      "\n",
      "Точность:\n",
      "0.3380281690140845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(test_ru, test_encoded, test_decoded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посимвольная точность небольшая, декодированный текст не понятен."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Раздел 2. Биграммы\n",
    "- подсчитаем частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "- проведем тестирование аналогично п.1, но при помощи биграмм.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_freq_bigram = get_ngram_freq(texts[0] + \" \" + texts[1], n_gram=2)\n",
    "encoded_freq_bigram = get_ngram_freq(test_encoded, n_gram=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping_bigram = generate_reverse_mapping(corpus_freq_bigram, encoded_freq_bigram, n_gram=2)\n",
    "test_decoded_bigram = apply_mapping(test_encoded, reverse_mapping_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст:\n",
      "только окончится один месяц сразу же начинается другой и ни разу еще не бывало так чтобы февраль пришел раньше чем уйдет январь а \n",
      "май обогнал бы апрель месяцы идут один за другим и никогда не встречаются но люди рассказывают будто в горной стране богемии была \n",
      "девочка которая видела все двенадцать месяцев сразу как же это случилось а вот как в одной маленькой деревушке жила злая и скупая \n",
      "женщина с дочкой и падчерицей дочку она любила а падчерица ничем ей не могла угодить что ни сделает падчерица  все не так как ни п\n",
      "овернется  все не в ту сторону  дочка по целым дням на перине валялась да пряники ела а падчерице с утра до ночи и присесть некогд\n",
      "а было то воды натаскай то хворосту из лесу привези то белье на речке выполощи то грядки в огороде выполи знала она и зимний холод\n",
      " и летний зной и весенний ветер и осенний дождь потомуто может и довелось ей однажды увидеть все двенадцать месяцев разом была зим\n",
      "а шел январь месяц снегу намело столько что от дверей его приходилось отгребать лопатами а в лесу на горе деревья стояли по пояс в\n",
      " сугробах и даже качаться не могли когда на них налетал ветер люди сидели в домах и топили печки\n",
      "\n",
      "Закодированный текст:\n",
      "ж ксщ т щ шымжяэт ймштучяэбтявльзточтшлымшлчжяэтйвзи цтмтшмтвльзтчнчтшчтдпалк тжлщтыж дптючавлкстхвмрчктвлшсрчтычутзцйчжтэшалвстлт\n",
      "улцт д ишлктдптлхвчкстучяэбптмйзжт ймштьлтйвзимутмтшмщ ийлтшчтаяжвчылфжяэтш ткфймтвляящльпалфжтдзйж тати вш цтяжвлшчтд ичуммтдпклт\n",
      "йча ыщлтщ ж влэтамйчклтаячтйачшлйблжстучяэбчатявльзтщлщточтгж тякзымк ястлта жтщлщтат йш цтулкчшсщ цтйчвчазрщчтомклтьклэтмтящзхлэт\n",
      "очшнмшлтятй ыщ цтмтхлйычвмбчцтй ыщзт шлткфдмклтлтхлйычвмблтшмычутчцтшчту иклтзи ймжстыж тшмтяйчклчжтхлйычвмблттаячтшчтжлщтщлщтшмтх\n",
      " ачвшчжяэттаячтшчтатжзтяж в шзттй ыщлтх тбчкпутйшэутшлтхчвмшчталкэклястйлтхвэшмщмтчклтлтхлйычвмбчтятзжвлтй тш ымтмтхвмячяжстшчщ ий\n",
      "лтдпк тж та йптшлжлящлцтж тъа в яжзтмьткчязтхвмачьмтж тдчксчтшлтвчыщчтапх к нмтж тивэйщмтат и в йчтапх кмтьшлклт шлтмтьмушмцтъ к й\n",
      "тмткчжшмцтьш цтмтачячшшмцтачжчвтмт ячшшмцтй ойстх ж узж ту очжтмтй ачк ястчцт йшлойптзамйчжстаячтйачшлйблжстучяэбчатвль утдпклтьму\n",
      "лтрчктэшалвстучяэбтяшчизтшлучк тяж ксщ тыж т жтйачвчцтчи тхвмъ ймк яст живчдлжстк хлжлумтлтаткчязтшлти вчтйчвчасэтяж экмтх тх эята\n",
      "тязив длътмтйлочтщлылжсяэтшчту икмтщ ийлтшлтшмътшлкчжлктачжчвткфймтямйчкмтатй улътмтж хмкмтхчыщм\n",
      "\n",
      "Декодированный текст:\n",
      "неняне енеслонон есос коон  ономь до солосоонон сньнея о со номь обо со десоне нон лнеде шосноня пносон носясо лок ьясон нссоня о \n",
      "коя еденсон де опноня коон е осьн есос мо сньнок о соненсо со соннолоунон се нусо нооономесоун дьсне с ненсея онносо денокоо дено \n",
      "соселно нененон сосоно соо ссосос оня коон ос ономь нон до шне оньлонеоя о сен нон с ессея коносянея соносьсно доно мнон о оньпон \n",
      "досбосо о селнея о послоно оя селнь есо нудоно о послоно о солок оя со кенно ьнесоня лне со осоноон послоно о  соо со нон нон со п\n",
      "есонсонон  соо со с нь оненесь  селно пе  онек сснк со поносо сонннооя со пннсоно оно о послоно о о ьнно се село о пнооооня соненс\n",
      "о дене не сесе сонооноя не хсенеонь ом нооь пносомо не доняо со нолно сепенебо не нннсно с ененесо сепено мсоно есо о моксоя хенес\n",
      " о нонсоя мсея о соооссоя сонон о еооссоя седся пенекьне кедон о сесонеоя оя ессодсе ьсосоня соо ссосос оня коон ос номек дено мок\n",
      "о сон нссоня коон  осонь соконе оненяне лне ен ссоноя оне пнохесонеоя енннодоня непоноко о с нооь со нено соносян оненно пе пено с\n",
      " оьннедох о содо нолоняон со кенно ненсо со сох сононон сонон нусо оосоно с секох о непоно полно\n",
      "\n",
      "Точность:\n",
      "0.2051056338028169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(test_ru, test_encoded, test_decoded_bigram)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат ухудшился, а вместе с ним и метрика, декодированный текст менее понятен прошлого варианта."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Раздел 3. MCMC-сэмплирование   \n",
    "- предложим метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "- реализуем и протестируем его, убедимся, что результаты улучшились.\n",
    "\n",
    "Будем использовать марковские цепи, представленные текстом разбитым на n-граммы, вероятность перехода между состояниями цепи - частота n-грамм. В качестве оценки считаем произведение всех встречающихся частот n-грамм. Для простоты вычислений используем логарифмическое правдоподобие. Применим алгоритм, основанный на MCMC, на каждой его итерации будем делать несколько циклов и брать в качестве окончательного результата лучший.\n",
    "- Вычисляем логарифм правдоподобия $p_{current}$;\n",
    "- Переставляем местами пару символов;\n",
    "- Восстанавливаем текст с новой перестановкой, вычисляем $p_{proposal}$;\n",
    "- Новая перестановка принимается с $p_{accept}$, возвращаемся ко второму пункту и повторяем цикл.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_freq_smoothed(text: str, n_gram: int=2):\n",
    "    vocab = len(set(text)) ** n_gram\n",
    "    if n_gram > 1:\n",
    "        text = [\"\".join(ngram) for ngram in everygrams(text, min_len=n_gram, max_len=n_gram)]\n",
    "\n",
    "    freq = {k: (v + 1) / (len(text) + vocab) for k, v in Counter(text).items()}\n",
    "    return freq\n",
    "\n",
    "\n",
    "def get_text_proba(\n",
    "        text: str, \n",
    "        mapping: Dict, \n",
    "        freq: Dict, \n",
    "        n_gram: int=2, \n",
    "        alphabet: str=ALPHABET_RU\n",
    "        ):\n",
    "    text_decoded = apply_mapping(text, mapping)\n",
    "    log_proba = 0\n",
    "    for i in range(len(text_decoded) - n_gram):\n",
    "        ngram = text_decoded[i : i + n_gram]\n",
    "        ngram_proba = freq.get(ngram, 1 / (len(text) + len(alphabet) ** n_gram))\n",
    "        log_proba += np.log(ngram_proba)\n",
    "    return log_proba\n",
    "\n",
    "\n",
    "def generate_reverse_mapping_mcmc(\n",
    "    text_encoded: str,\n",
    "    corpus_freq: Dict,\n",
    "    alphabet_encoded: str=ALPHABET_RU,\n",
    "    alphabet_corpus: str=ALPHABET_RU,\n",
    "    n_iters: int=20000,\n",
    "    n_trials: int=20,\n",
    "    n_gram: int=2,\n",
    "):\n",
    "    mappings = []\n",
    "    best_reverse_mapping = None\n",
    "    best_log_likelihood = - np.inf\n",
    "\n",
    "    for _ in tqdm(range(n_trials), total=n_trials):\n",
    "        alphabet_encoded = list(alphabet_encoded)\n",
    "        alphabet_corpus = list(alphabet_corpus)\n",
    "        reverse_mapping = {k: v for k, v in zip(alphabet_encoded, alphabet_corpus[: len(alphabet_encoded)])}\n",
    "\n",
    "        log_proba_current = get_text_proba(text_encoded, reverse_mapping, corpus_freq, n_gram=n_gram)\n",
    "\n",
    "        for _ in range(n_iters):\n",
    "            alphabet_proposal = alphabet_corpus[:]\n",
    "            id_1, id_2 = np.random.choice(len(alphabet_proposal), replace=False, size=2)\n",
    "            alphabet_proposal[id_1], alphabet_proposal[id_2] = alphabet_proposal[id_2], alphabet_proposal[id_1]\n",
    "\n",
    "            reverse_mapping_proposal = {k: v for k, v in zip(alphabet_encoded, alphabet_proposal[: len(alphabet_encoded)])}\n",
    "            log_proba_proposal = get_text_proba(text_encoded, reverse_mapping_proposal, corpus_freq, n_gram=n_gram)\n",
    "\n",
    "            p = np.exp(log_proba_proposal - log_proba_current)\n",
    "\n",
    "            if p > np.random.rand():\n",
    "                alphabet_corpus = alphabet_proposal\n",
    "                log_proba_current = log_proba_proposal\n",
    "                reverse_mapping = reverse_mapping_proposal\n",
    "\n",
    "        if log_proba_current > best_log_likelihood:\n",
    "            best_log_likelihood = log_proba_current\n",
    "            best_reverse_mapping = reverse_mapping\n",
    "\n",
    "        mappings.append(reverse_mapping)\n",
    "\n",
    "    print(f\"Log likelihood: {best_log_likelihood}\")\n",
    "\n",
    "    return best_reverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [07:19<00:00, 21.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood: -6249.856327986885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_freq = get_ngram_freq_smoothed(texts[0] + \" \" + texts[1], n_gram=2)\n",
    "reverse_mapping_mcmc = generate_reverse_mapping_mcmc(test_encoded, corpus_freq)\n",
    "test_decoded_mcmc = apply_mapping(test_encoded, reverse_mapping_mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст:\n",
      "только окончится один месяц сразу же начинается другой и ни разу еще не бывало так чтобы февраль пришел раньше чем уйдет январь а \n",
      "май обогнал бы апрель месяцы идут один за другим и никогда не встречаются но люди рассказывают будто в горной стране богемии была \n",
      "девочка которая видела все двенадцать месяцев сразу как же это случилось а вот как в одной маленькой деревушке жила злая и скупая \n",
      "женщина с дочкой и падчерицей дочку она любила а падчерица ничем ей не могла угодить что ни сделает падчерица  все не так как ни п\n",
      "овернется  все не в ту сторону  дочка по целым дням на перине валялась да пряники ела а падчерице с утра до ночи и присесть некогд\n",
      "а было то воды натаскай то хворосту из лесу привези то белье на речке выполощи то грядки в огороде выполи знала она и зимний холод\n",
      " и летний зной и весенний ветер и осенний дождь потомуто может и довелось ей однажды увидеть все двенадцать месяцев разом была зим\n",
      "а шел январь месяц снегу намело столько что от дверей его приходилось отгребать лопатами а в лесу на горе деревья стояли по пояс в\n",
      " сугробах и даже качаться не могли когда на них налетал ветер люди сидели в домах и топили печки\n",
      "\n",
      "Закодированный текст:\n",
      "ж ксщ т щ шымжяэт ймштучяэбтявльзточтшлымшлчжяэтйвзи цтмтшмтвльзтчнчтшчтдпалк тжлщтыж дптючавлкстхвмрчктвлшсрчтычутзцйчжтэшалвстлт\n",
      "улцт д ишлктдптлхвчкстучяэбптмйзжт ймштьлтйвзимутмтшмщ ийлтшчтаяжвчылфжяэтш ткфймтвляящльпалфжтдзйж тати вш цтяжвлшчтд ичуммтдпклт\n",
      "йча ыщлтщ ж влэтамйчклтаячтйачшлйблжстучяэбчатявльзтщлщточтгж тякзымк ястлта жтщлщтат йш цтулкчшсщ цтйчвчазрщчтомклтьклэтмтящзхлэт\n",
      "очшнмшлтятй ыщ цтмтхлйычвмбчцтй ыщзт шлткфдмклтлтхлйычвмблтшмычутчцтшчту иклтзи ймжстыж тшмтяйчклчжтхлйычвмблттаячтшчтжлщтщлщтшмтх\n",
      " ачвшчжяэттаячтшчтатжзтяж в шзттй ыщлтх тбчкпутйшэутшлтхчвмшчталкэклястйлтхвэшмщмтчклтлтхлйычвмбчтятзжвлтй тш ымтмтхвмячяжстшчщ ий\n",
      "лтдпк тж та йптшлжлящлцтж тъа в яжзтмьткчязтхвмачьмтж тдчксчтшлтвчыщчтапх к нмтж тивэйщмтат и в йчтапх кмтьшлклт шлтмтьмушмцтъ к й\n",
      "тмткчжшмцтьш цтмтачячшшмцтачжчвтмт ячшшмцтй ойстх ж узж ту очжтмтй ачк ястчцт йшлойптзамйчжстаячтйачшлйблжстучяэбчатвль утдпклтьму\n",
      "лтрчктэшалвстучяэбтяшчизтшлучк тяж ксщ тыж т жтйачвчцтчи тхвмъ ймк яст живчдлжстк хлжлумтлтаткчязтшлти вчтйчвчасэтяж экмтх тх эята\n",
      "тязив длътмтйлочтщлылжсяэтшчту икмтщ ийлтшлтшмътшлкчжлктачжчвткфймтямйчкмтатй улътмтж хмкмтхчыщм\n",
      "\n",
      "Декодированный текст:\n",
      "только окончится один месяц сразу же начинается другой и ни разу еще не бывало так чтобы февраль пришел раньше чем уйдет январь а \n",
      "май обогнал бы апрель месяцы идут один за другим и никогда не встречаются но люди рассказывают будто в горной стране богемии была \n",
      "девочка которая видела все двенадцать месяцев сразу как же это случилось а вот как в одной маленькой деревушке жила злая и скупая \n",
      "женщина с дочкой и падчерицей дочку она любила а падчерица ничем ей не могла угодить что ни сделает падчерица  все не так как ни п\n",
      "овернется  все не в ту сторону  дочка по целым дням на перине валялась да пряники ела а падчерице с утра до ночи и присесть некогд\n",
      "а было то воды натаскай то хворосту из лесу привези то белье на речке выполощи то грядки в огороде выполи знала она и зимний холод\n",
      " и летний зной и весенний ветер и осенний дождь потомуто может и довелось ей однажды увидеть все двенадцать месяцев разом была зим\n",
      "а шел январь месяц снегу намело столько что от дверей его приходилось отгребать лопатами а в лесу на горе деревья стояли по пояс в\n",
      " сугробах и даже качаться не могли когда на них налетал ветер люди сидели в домах и топили печки\n",
      "\n",
      "Точность:\n",
      "1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(test_ru, test_encoded, test_decoded_mcmc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат приятно удивляет, точное полное декодирование."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Раздел 4. Расшифровка сообщения  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:22<00:00,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood: -1232.8845821292682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_freq = get_ngram_freq(texts[0] + \" \" + texts[1])\n",
    "msg_freqs = get_ngram_freq(msg)\n",
    "\n",
    "corpus_freq_sorted = sorted(corpus_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "msg_freq_sorted = sorted(msg_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "alphabet_corpus = \"\".join([char for char, _ in corpus_freq_sorted])\n",
    "alphabet_encoded = \"\".join([char for char, _ in msg_freq_sorted])\n",
    "\n",
    "corpus_freq = get_ngram_freq_smoothed(texts[0] + \" \" + texts[1], n_gram=2)\n",
    "reverse_mapping_msg = generate_reverse_mapping_mcmc(\n",
    "    msg,\n",
    "    alphabet_encoded=alphabet_encoded,\n",
    "    alphabet_corpus=alphabet_corpus,\n",
    "    corpus_freq=corpus_freq\n",
    ")\n",
    "msg_decoded = apply_mapping(msg, reverse_mapping_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст:\n",
      "если вы видите нормальный или почти нормальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правиль\n",
      "но и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обещаю\n",
      "\n",
      "Закодированный текст:\n",
      "დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵი\n",
      "სႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ\n",
      "\n",
      "Декодированный текст:\n",
      "если вы вимите нордальный или почти нордальный текст у этого соожшения который легко прочитать скорее всего вы все смелали правиль\n",
      "но и получите даксидальный жалл за послемнее четвертое замание курса ботя конечно я ничего не ожешаю\n",
      "\n",
      "Точность:\n",
      "0.9391304347826087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "present_msg = \"если вы видите нормальный или почти нормальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обещаю\"\n",
    "describe(present_msg, msg, msg_decoded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметна путаница с буквами \"м\" / \"д\", \"б\" / \"ж\", \"щ\" и \"х\", но смысл сообщения улавливается."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Раздел 5. Триграммы\n",
    "А что если от биграмм перейти к триграммам (тройкам букв) или даже больше? Улучшатся ли результаты? Когда улучшатся, а когда нет? Чтобы ответить на этот вопрос эмпирически, уже может понадобиться погенерировать много тестовых перестановок и последить за метриками, глазами может быть и не видно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:16<00:00,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood: -1851.4135910201478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_freq = get_ngram_freq(texts[0] + \" \" + texts[1])\n",
    "msg_freqs = get_ngram_freq(msg)\n",
    "\n",
    "corpus_freq_sorted = sorted(corpus_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "msg_freq_sorted = sorted(msg_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "alphabet_corpus = \"\".join([char for char, _ in corpus_freq_sorted])\n",
    "alphabet_encoded = \"\".join([char for char, _ in msg_freq_sorted])\n",
    "\n",
    "corpus_freq_trigram = get_ngram_freq_smoothed(texts[0] + \" \" + texts[1], n_gram=3)\n",
    "reverse_mapping_msg_trigram = generate_reverse_mapping_mcmc(\n",
    "    msg,\n",
    "    alphabet_encoded=alphabet_encoded,\n",
    "    alphabet_corpus=alphabet_corpus,\n",
    "    corpus_freq=corpus_freq_trigram,\n",
    "    n_iters=10000,\n",
    "    n_trials=10,\n",
    "    n_gram=3\n",
    ")\n",
    "msg_decoded_trigram = apply_mapping(msg, reverse_mapping_msg_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст:\n",
      "если вы видите нормальный или почти нормальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правиль\n",
      "но и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обещаю\n",
      "\n",
      "Закодированный текст:\n",
      "დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵი\n",
      "სႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ\n",
      "\n",
      "Декодированный текст:\n",
      "если жт жидине вормалывть или почни вормалывть нексн у эного сообщевия конорть легко прочинаны скорее жсего жт жсе сделали пражилы\n",
      "во и получине максималывть балл за последвее ченжерное задавие курса хоня ковечво я вичего ве обещац\n",
      "\n",
      "Точность:\n",
      "0.7913043478260869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(present_msg, msg, msg_decoded_trigram)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Раздел 6. Применение модели\n",
    "Данная модель может быть применима для работы с последовательностями ДНК, например, для сопоставления определенных генетических последовательностей, которые могут быть расшифрованы в соответствии с определенными признаками организма или для оценки взаимодействий генов между собой."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
